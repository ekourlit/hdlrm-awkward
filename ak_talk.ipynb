{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5b3cbee-56cd-402f-82fc-9479119acd4b",
   "metadata": {},
   "source": [
    "# Preprocessing arbitrarily structured data for AI with Awkward Array\n",
    "\n",
    "**Vangelis Kourlitis, Technical University of Munich**  \n",
    "*vangelis.kourlitis@cern.ch*  \n",
    "\n",
    "Jim Pivarsky, Princeton University  \n",
    "*pivarski@princeton.edu*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ac8a2c",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a210ca-3289-4d36-8617-63a562849a7a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Usually the arrays you deal with are rectangular (in $n$ dimensions; \"rectilinear\").\n",
    "\n",
    "<center>\n",
    "<img src=\"img/8-layer_cube.jpg\" width=\"50%\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b3d7bc-bd9f-4be3-8591-31438d04848b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "What if we had data like this?\n",
    "\n",
    "```json\n",
    "[\n",
    "  [[1.84, 0.324]],\n",
    "  [[-1.609, -0.713, 0.005], [0.953, -0.993, 0.011, 0.718]],\n",
    "  [[0.459, -1.517, 1.545], [0.33, 0.292]],\n",
    "  [[-0.376, -1.46, -0.206], [0.65, 1.278]],\n",
    "  [[], [], [1.617]],\n",
    "  []\n",
    "]\n",
    "[\n",
    "  [[-0.106, 0.611]],\n",
    "  [[0.118, -1.788, 0.794, 0.658], [-0.105]]\n",
    "]\n",
    "[\n",
    "  [[-0.384], [0.697, -0.856]],\n",
    "  [[0.778, 0.023, -1.455, -2.289], [-0.67], [1.153, -1.669, 0.305, 1.517, -0.292]]\n",
    "]\n",
    "[\n",
    "  [[0.205, -0.355], [-0.265], [1.042]],\n",
    "  [[-0.004], [-1.167, -0.054, 0.726, 0.213]],\n",
    "  [[1.741, -0.199, 0.827]]\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47dd75e-f5c7-4a86-946f-984b6cf7f3e6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Or **heterogenous** data like this?\n",
    "\n",
    "```json\n",
    "[\n",
    "  {\"fill\": \"#b1b1b1\", \"stroke\": \"none\", \"points\": [{\"x\": 5.27453, \"y\": 1.03276},\n",
    "    {\"x\": -3.51280, \"y\": 1.74849}]},\n",
    "  {\"fill\": \"#b1b1b1\", \"stroke\": \"none\", \"points\": [{\"x\": 8.21630, \"y\": 4.07844},\n",
    "    {\"x\": -0.79157, \"y\": 3.49478}, {\"x\": 16.38932, \"y\": 5.29399},\n",
    "    {\"x\": 10.38641, \"y\": 0.10832}, {\"x\": -2.07070, \"y\": 14.07140},\n",
    "    {\"x\": 9.57021, \"y\": -0.94823}, {\"x\": 1.97332, \"y\": 3.62380},\n",
    "    {\"x\": 5.66760, \"y\": 11.38001}, {\"x\": 0.25497, \"y\": 3.39276},\n",
    "    {\"x\": 3.86585, \"y\": 6.22051}, {\"x\": -0.67393, \"y\": 2.20572}]},\n",
    "  {\"fill\": \"#d0d0ff\", \"stroke\": \"none\", \"points\": [{\"x\": 3.59528, \"y\": 7.37191},\n",
    "    {\"x\": 0.59192, \"y\": 2.91503}, {\"x\": 4.02932, \"y\": -1.13601},\n",
    "    {\"x\": -1.01593, \"y\": 1.95894}, {\"x\": 1.03666, \"y\": 0.05251}]},\n",
    "  {\"fill\": \"#d0d0ff\", \"stroke\": \"none\", \"points\": [{\"x\": -8.78510, \"y\": -0.00497},\n",
    "    {\"x\": -15.22688, \"y\": 3.90244}, {\"x\": 5.74593, \"y\": 4.12718}]},\n",
    "  {\"fill\": \"none\", \"stroke\": \"#000000\", \"points\": [{\"x\": 4.40625, \"y\": -6.953125},\n",
    "    {\"x\": 4.34375, \"y\": -7.09375}, {\"x\": 4.3125, \"y\": -7.140625},\n",
    "    {\"x\": 4.140625, \"y\": -7.140625}]},\n",
    "  {\"fill\": \"none\", \"stroke\": \"#808080\", \"points\": [{\"x\": 0.46875, \"y\": -0.09375},\n",
    "    {\"x\": 0.46875, \"y\": -0.078125}, {\"x\": 0.46875, \"y\": 0.53125}]}\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f27a1fc-1ff9-4ada-b6b0-1fab7ae89276",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "<br>\n",
    "\n",
    "Real scientific datasets feature complex, irregular structures due to nested or variable-sized outputs from different sensors, or due to missing data values. The data can be also of mixed types or **heterogeneous**. Thus some level of data cleaning is almost always required.\n",
    "\n",
    "**Goal**: process arbitrary data structure with array-oriented interface and performance...\n",
    "\n",
    "<center>\n",
    "<img src=\"img/awkward-motivation-venn-diagram.svg\" width=\"40%\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfa260f-3e77-4989-a667-0d5da0dbee1a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Libraries for irregular arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4aeb59-6edf-4a5f-a00b-715e51f22faa",
   "metadata": {
    "tags": []
   },
   "source": [
    "<table>\n",
    "<tr style=\"background: white;\"><td width=\"35%\"><img src=\"img/logo-arrow.svg\" width=\"100%\"></td><td style=\"padding-left: 50px;\">In-memory format and an ecosystem of tools, an \"exploded database\" (database functionality provided as interchangeable pieces). Strong focus on delivering data, zero-copy, between processes.</td></tr>\n",
    "<tr style=\"background: white; height: 30px;\"><td></td><td></td></tr>\n",
    "<tr style=\"background: white;\"><td width=\"35%\"><img src=\"img/logo-awkward.svg\" width=\"100%\"></td><td style=\"padding-left: 50px;\">Library for array-oriented programming like NumPy, but for arbitrary data structures. Losslessly zero-copy convertible to/from Arrow and Parquet.</td></tr>\n",
    "<tr style=\"background: white; height: 30px;\"><td></td><td></td></tr>\n",
    "<tr style=\"background: white;\"><td width=\"35%\"><img src=\"img/logo-parquet.svg\" width=\"100%\"></td><td style=\"padding-left: 50px;\">Disk format for storing large datasets and (selectively) retrieving them.</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fc76c9-290a-49cd-ab6c-0065e8c94573",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<img src=\"img/logo-arrow.svg\" width=\"30%\">\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18a43904-14bd-4edc-b6fd-cd9af40da40a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pyarrow as pa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6c737c-10b1-4259-aa11-7f0d4cdf86d8",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f45c5b81-625d-4680-987e-a1eee32d968c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "arrow_array = pa.array([\n",
    "    [{\"x\": 1.1, \"y\": [1]}, {\"x\": 2.2, \"y\": [1, 2]}, {\"x\": 3.3, \"y\": [1, 2, 3]}],\n",
    "    [],\n",
    "    [{\"x\": 4.4, \"y\": [1, 2, 3, 4]}, {\"x\": 5.5, \"y\": [1, 2, 3, 4, 5]}]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7dff00-f312-4011-b62f-b7d21a71aa8b",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ba0e82-f1c1-4db1-bce3-098ff07e4994",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "arrow_array.type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c2eb4d-8ff8-4fd0-a897-91a1d5f7d929",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57bc1f2-4db4-49d7-8928-f4fa8d26620f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<img src=\"img/logo-awkward.svg\" width=\"30%\">\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74f36f06-325c-45d1-8d38-3f21c6d2a827",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import awkward as ak"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3274cf50-1870-468f-a240-49e8f2d625a8",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79beb7b-8df8-410b-a103-551c1fa16ad1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "awkward_array = ak.from_arrow(arrow_array)\n",
    "awkward_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36241997-055b-4fff-974a-9f48bef5d7d4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<img src=\"img/logo-parquet.svg\" width=\"30%\">\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3087fd-f3ea-45e0-9fa6-d4202490c5ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ak.to_parquet(awkward_array, \"/tmp/file.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae99fd9d-45bd-46e3-adcc-1036b4d4a656",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f348a947-d770-4526-9bfd-f73635d5831b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ak.from_parquet(\"/tmp/file.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685aad8a-f0eb-4e25-91d7-6ebc4bfe9d47",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Awkward Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3ad23dd-4165-4cb2-a3f4-361e4ddabbbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ragged = ak.Array([\n",
    "    [\n",
    "      [[1.84, 0.324]],\n",
    "      [[-1.609, -0.713, 0.005], [0.953, -0.993, 0.011, 0.718]],\n",
    "      [[0.459, -1.517, 1.545], [0.33, 0.292]],\n",
    "      [[-0.376, -1.46, -0.206], [0.65, 1.278]],\n",
    "      [[], [], [1.617]],\n",
    "      []\n",
    "    ],\n",
    "    [\n",
    "      [[-0.106, 0.611]],\n",
    "      [[0.118, -1.788, 0.794, 0.658], [-0.105]]\n",
    "    ],\n",
    "    [\n",
    "      [[-0.384], [0.697, -0.856]],\n",
    "      [[0.778, 0.023, -1.455, -2.289], [-0.67], [1.153, -1.669, 0.305, 1.517, -0.292]]\n",
    "    ],\n",
    "    [\n",
    "      [[0.205, -0.355], [-0.265], [1.042]],\n",
    "      [[-0.004], [-1.167, -0.054, 0.726, 0.213]],\n",
    "      [[1.741, -0.199, 0.827]]\n",
    "    ]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55509b2-735a-4bd7-99e8-1e3a0f4482da",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "**Multidimensional indexing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e71258-eb17-4aa7-a088-cddefcc80efd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ragged[3, 1, -1, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26d50ec-8341-400f-9315-bb6cc9514537",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Basic slicing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20087e7-629f-43e7-aaee-d9da62dba40c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ragged[3, 1:, -1, 1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e93ac5-f284-423d-a058-07f8bd70f956",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "**Awkward slicing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a09bc1-8417-426f-8b13-752c4ce33601",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ragged > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c725196-44f2-4aa6-aaf8-c6cd93ea71ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ragged[ragged > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd55c25-f4d1-4144-a0dd-0544db811f5e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "**Reductions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba071c4-4c24-4c5a-8619-1665fef31f2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ak.sum(ragged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4238ba79-2b8b-491b-82a1-e073a0dc0679",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ak.sum(ragged, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c72ab16-0ac5-4aa9-865f-bd7a975f43cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ak.sum(ragged, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578d3cab-92a0-44bf-a05e-3c3a5b1af8cb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "How are reductions even defined for ragged arrays?\n",
    "\n",
    "<center>\n",
    "<img src=\"img/example-reduction-sum.svg\" width=\"50%\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60666be7",
   "metadata": {},
   "source": [
    "Let's demonstrate it with a small example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4fb2dce-818f-4cae-b737-38a7b72d1e25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "small_ragged = ak.Array([[   1, 2, 4],\n",
    "                         [          ],\n",
    "                         [None, 8,  ],\n",
    "                         [  16      ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb46960-bdae-431c-bc33-c3cfc52be9cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ak.sum(small_ragged, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e853227",
   "metadata": {},
   "source": [
    "### Heterogenous data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dbe25c13-98be-4496-a857-dab7658b092f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "structured = ak.Array([\n",
    "  {\"fill\": \"#b1b1b1\", \"stroke\": \"none\", \"points\": [{\"x\": 5.27453, \"y\": 1.03276},\n",
    "    {\"x\": -3.51280, \"y\": 1.74849}]},\n",
    "  {\"fill\": \"#b1b1b1\", \"stroke\": \"none\", \"points\": [{\"x\": 8.21630, \"y\": 4.07844},\n",
    "    {\"x\": -0.79157, \"y\": 3.49478}, {\"x\": 16.38932, \"y\": 5.29399},\n",
    "    {\"x\": 10.38641, \"y\": 0.10832}, {\"x\": -2.07070, \"y\": 14.07140},\n",
    "    {\"x\": 9.57021, \"y\": -0.94823}, {\"x\": 1.97332, \"y\": 3.62380},\n",
    "    {\"x\": 5.66760, \"y\": 11.38001}, {\"x\": 0.25497, \"y\": 3.39276},\n",
    "    {\"x\": 3.86585, \"y\": 6.22051}, {\"x\": -0.67393, \"y\": 2.20572}]},\n",
    "  {\"fill\": \"#d0d0ff\", \"stroke\": \"none\", \"points\": [{\"x\": 3.59528, \"y\": 7.37191},\n",
    "    {\"x\": 0.59192, \"y\": 2.91503}, {\"x\": 4.02932, \"y\": -1.13601},\n",
    "    {\"x\": -1.01593, \"y\": 1.95894}, {\"x\": 1.03666, \"y\": 0.05251}]},\n",
    "  {\"fill\": \"#d0d0ff\", \"stroke\": \"none\", \"points\": [{\"x\": -8.78510, \"y\": -0.00497},\n",
    "    {\"x\": -15.22688, \"y\": 3.90244}, {\"x\": 5.74593, \"y\": 4.12718}]},\n",
    "  {\"fill\": \"none\", \"stroke\": \"#000000\", \"points\": [{\"x\": 4.40625, \"y\": -6.953125},\n",
    "    {\"x\": 4.34375, \"y\": -7.09375}, {\"x\": 4.3125, \"y\": -7.140625},\n",
    "    {\"x\": 4.140625, \"y\": -7.140625}]},\n",
    "  {\"fill\": \"none\", \"stroke\": \"#808080\", \"points\": [{\"x\": 0.46875, \"y\": -0.09375},\n",
    "    {\"x\": 0.46875, \"y\": -0.078125}, {\"x\": 0.46875, \"y\": 0.53125}]}\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f2f95a",
   "metadata": {},
   "source": [
    "A lot of times you can use Awkward and Numpy interchangeably."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d1523ff-2e39-4ec0-a5b3-9f45591a0544",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d933bfd1-c886-41b3-ad53-688283440b20",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "**Elementwise formulas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1e4c5d-9660-451f-9fdd-3536c005ed55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.sqrt(structured[\"points\", \"x\"]**2 + structured[\"points\", \"y\"]**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc89b4de",
   "metadata": {},
   "source": [
    "Alternative (and maybe more convenient) formulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be00be97-c4d5-48ff-ae34-712b84c390b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.sqrt(structured.points.x**2 + structured.points.y**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b4222d",
   "metadata": {},
   "source": [
    "Let's do an example calculation on those heterogenous data. Each row stores a `fill` color and a set of `points` in `x` and `y` coordinates, among other information. Consecutive `points` define _segments_ and the segments define a total _path_. We want to calculate the `fill` color of the path with the largest length.\n",
    "\n",
    "We will calculate the length of the path in each row by summing the segment lengths $\\displaystyle \\sum_i^{n - 1} \\Delta r_i$, where the segment length $\\Delta r_i = \\sqrt{\\Delta x_i^2 + \\Delta y_i^2}$\n",
    "\n",
    "<br>\n",
    "\n",
    "<center>\n",
    "<img src=\"img/length-by-segment.svg\" width=\"50%\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08160a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_length = np.sum(\n",
    "    np.sqrt(\n",
    "        (structured.points.x[:, 1:] - structured.points.x[:, 0:-1])**2 + (structured.points.y[:, 1:] - structured.points.y[:, 0:-1])**2\n",
    "        )\n",
    "    , axis=-1)\n",
    "display(paths_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf19978",
   "metadata": {},
   "outputs": [],
   "source": [
    "color = structured[ np.argmax( paths_length ) ].fill\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "display(Markdown(\n",
    "    f'<span style=\"font-family: monospace\">{color} <span style=\"color: {color}\">████████</span></span>'\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827bf2c4",
   "metadata": {},
   "source": [
    "### GPU capabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b1914f",
   "metadata": {},
   "source": [
    "CUDA GPU kernels have been developed for a lot of Awkward operations (more currently under developments) thus Awkward array data can be to the device and the number crunching happens accelerated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1304d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the exmple ragged array from above\n",
    "array_cpu = ragged\n",
    "ak.backend(array_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54ffc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# move to the device\n",
    "array_gpu = ak.to_backend(array_cpu, \"cuda\")\n",
    "ak.backend(array_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c721e48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat the same calculation as above but on the divice\n",
    "structured_gpu = ak.to_backend(structured, \"cuda\")\n",
    "array_sum = np.sum(np.sqrt((structured_gpu.points.x[:, 1:] - structured_gpu.points.x[:, 0:-1])**2 + (structured_gpu.points.y[:, 1:] - structured_gpu.points.y[:, 0:-1])**2), axis=-1)\n",
    "\n",
    "# display\n",
    "display(array_sum[array_sum > 10]) # selection/indexing\n",
    "display(array_sum[array_sum < 10]) # selection/indexing\n",
    "\n",
    "# everything stays in the device\n",
    "ak.backend(array_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94536394-aa7d-41a9-8c22-d55e6faa5d06",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Bonus: Combinatorics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5624b269-5725-430e-8e6c-35df59f483ee",
   "metadata": {},
   "source": [
    "Some operations are more meaningful on irregular arrays than rectilinear ones:\n",
    "\n",
    "<table style=\"width: 60%\">\n",
    "<tr style=\"background: white; padding-top: 0px;\"><td width=\"50%\"><img src=\"img/cartoon-cartesian.svg\" width=\"100%\"></td><td width=\"50%\"><img src=\"img/cartoon-combinations.svg\" width=\"100%\"></td></tr>\n",
    "</table>\n",
    "\n",
    "[ak.cartesian](https://awkward-array.org/doc/main/reference/generated/ak.cartesian.html) takes a [Cartesian product](https://en.wikipedia.org/wiki/Cartesian_product) of lists from $n$ different arrays, making an array of lists of $n$-tuples.\n",
    "\n",
    "[ak.combinations](https://awkward-array.org/doc/main/reference/generated/ak.combinations.html) takes $n$ [samples without replacement](http://prob140.org/sp18/textbook/notebooks-md/5_04_Sampling_Without_Replacement.html) of lists from a single array, making an array of lists of $n$-tuples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f287196-4044-4585-be8f-354634226451",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<center>\n",
    "<img src=\"img/cartoon-cartesian.svg\" width=\"30%\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf80340c-0348-4641-9c76-34ac7585efcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "numbers = ak.Array([[1, 2, 3], [], [4]])\n",
    "letters = ak.Array([[\"a\", \"b\"], [\"c\"], [\"d\", \"e\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c960d4e-b790-4e75-a6dd-8d27548fd8e1",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc5d7d9-6e1e-4721-aadf-4a0becb0b4e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ak.cartesian([numbers, letters])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98047723-2a46-49fa-a704-a3a7ef52625b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<center>\n",
    "<img src=\"img/cartoon-combinations.svg\" width=\"30%\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cfad842c-b3a2-46bd-b98e-e86a3dd42d9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "values = ak.Array([[1.1, 2.2, 3.3, 4.4], [], [5.5, 6.6]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fb2d0b-20e1-49b4-b3ef-4e1cd69e310f",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1070a7-3c1a-4057-b129-36666b88f24d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ak.combinations(values, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1550b4d8",
   "metadata": {},
   "source": [
    "## Awkward as a pre-processor\n",
    "\n",
    "Awkward Array helps transform data from its raw source into a format that machine learning (ML) models can use. Whether that involves padding data with zeros and applying masks for fixed-dimension inputs or providing data directly to models that support truly ragged arrays, Awkward Array makes this process easier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c556e725",
   "metadata": {},
   "source": [
    "Let's demonstrate that using some real HEP (ragged) data from the ATLAS experiment! ATLAS has recently released 65 TB of PHYSLITE open data for research -- this is over 7 billion LHC collision events! Those are all the data collected by the experiment during the 2015 and 2016. The release is accompanied by additional 2 billion events of simulated “Monte Carlo” data, which are essential for carrying out a physics analysis. The simulated data have largely the same structure as the real data. We're going to use these simulated events for today's demonstration for practical purposes.\n",
    "\n",
    "Read about our open data release at: \n",
    "\n",
    "https://atlas.cern/Updates/News/Open-Data-Research\n",
    "\n",
    "Our open data portal provides in depth information about the data along with analysis tutorials:\n",
    "\n",
    "https://opendata.atlas.cern/\n",
    "\n",
    "The properties of the particles we store in those files are all listed in:\n",
    "\n",
    "https://atlas-physlite-content-opendata.web.cern.ch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9db52b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot # the HEP-specific library to read the ATLAS data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5fc66e",
   "metadata": {},
   "source": [
    "You can download some example data (DOI:[10.7483/OPENDATA.ATLAS.K5SU.X65Y](http://doi.org/10.7483/OPENDATA.ATLAS.K5SU.X65Y)) with:  \n",
    "`wget https://opendata.cern.ch/record/80010/files/assets/atlas/rucio/mc20_13TeV/DAOD_PHYSLITE.37621317._000001.pool.root.1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "50c89388",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_file = '/afs/ipp-garching.mpg.de/home/e/eveko/ptmp/samples/DAOD_PHYSLITE.37621317._000001.pool.root.1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d2e6897b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with uproot.open({example_file: 'CollectionTree'}) as tree:\n",
    "    el_pt = tree[\"AnalysisElectronsAuxDyn.pt\"].array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff1a874",
   "metadata": {},
   "outputs": [],
   "source": [
    "el_pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10598073",
   "metadata": {},
   "source": [
    "### Padding & Masking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c011dc",
   "metadata": {},
   "source": [
    "Often ML frameworks and algorithms require rectilinear data structures. Awkward can help on cleaning and selecting ragged data and then deliver rectilinear arrays that can be converted to tensors. We will demonstrate how to pad and extract masks from rectilinear data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a29954f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select events (rows) with at least one electron (column) with pt > 20000 MeV\n",
    "selected_el_pt = el_pt[ el_pt > 20000 ]\n",
    "selected_el_pt = selected_el_pt[ ak.num( selected_el_pt ) > 0 ]\n",
    "display(selected_el_pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8c5231",
   "metadata": {},
   "source": [
    "Let's first pad each row of the data with `None` values. We need to set the maximum length of the row. We will estimate that from the data themselves (`max_num_el`). The result will be a rectilinear array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c49b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the maximum number of electrons (columns) in each event (rows)?\n",
    "max_num_el = np.max(ak.num(selected_el_pt, axis=1))\n",
    "padded_el_pt = ak.pad_none(selected_el_pt, max_num_el)\n",
    "display(padded_el_pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e031e2ee",
   "metadata": {},
   "source": [
    "Before we substitute `None` with any value, we can extract a mask that might be helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6723c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ak.is_none(padded_el_pt, axis=1)\n",
    "display(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6371f816",
   "metadata": {},
   "source": [
    "Finally, we can substitute `None` with a default value, e.g. 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e0b8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_el_pt = ak.fill_none(padded_el_pt, 0)\n",
    "display(padded_el_pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa088a22",
   "metadata": {},
   "source": [
    "Let's import `torch` and convert the above rectilinear array to a tensor in the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "064bea8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9233d131",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor( padded_el_pt, dtype=torch.float32, device='cuda' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53863840",
   "metadata": {},
   "source": [
    "Unfortunately, this **currently** fails:   \n",
    "`torch.tensor( selected_el_pt, dtype=torch.float32, device='cuda' )`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ce3cc3",
   "metadata": {},
   "source": [
    "### Bonus: Incorporating into PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "609567d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import vector\n",
    "vector.register_awkward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cdce671f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RootDataset(Dataset):\n",
    "    def __init__(self, root_file):\n",
    "        super().__init__()\n",
    "        self.root_file = root_file\n",
    "        self.event_data = None\n",
    "        self.preload_data()\n",
    "\n",
    "    def preload_data(self):\n",
    "        with uproot.open({self.root_file: 'CollectionTree'}) as tree:\n",
    "            jets = ak.zip({\n",
    "                \"pt\": tree[\"AnalysisJetsAuxDyn.pt\"].array(), # float\n",
    "                \"eta\": tree[\"AnalysisJetsAuxDyn.eta\"].array(), # float\n",
    "                \"phi\": tree[\"AnalysisJetsAuxDyn.phi\"].array(), # float\n",
    "                \"mass\": tree[\"AnalysisJetsAuxDyn.m\"].array() # float\n",
    "            }, with_name='Momentum4D')\n",
    "            jets[\"QGTagger_NTracks\"] = tree[\"AnalysisJetsAuxDyn.DFCommonJets_QGTagger_NTracks\"].array() # int\n",
    "        \n",
    "        # select events with at least two jets\n",
    "        self.event_data = jets[ak.num(jets, axis=-1) >= 2]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.event_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        jets = self.event_data[idx]\n",
    "        \n",
    "        # use the pair of jets with minimum delta R\n",
    "        candidates = ak.combinations(jets, 2, axis=-1)\n",
    "        jets1, jets2 = ak.unzip(candidates)\n",
    "        delta_r = jets1.deltaR(jets2)\n",
    "        candidates = candidates[ ak.argmin(delta_r, keepdims=True) ] \n",
    "        \n",
    "        # ugly convolved line but it doesn't matter\n",
    "        candidates_list = list( map(lambda x: list(x.values()), ak.to_list(candidates[0])) )\n",
    "        features_tensor = torch.flatten( torch.tensor( candidates_list, dtype=torch.float32 ) )\n",
    "        \n",
    "        return features_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "53a09542",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = RootDataset(example_file)\n",
    "dataloader = DataLoader(dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7430faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the DataLoader\n",
    "for batch in dataloader:\n",
    "    # move to the device\n",
    "    batch = batch.cuda()\n",
    "    # show\n",
    "    display(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b482b5fa",
   "metadata": {},
   "source": [
    "### Graphs in PyTorch Geometric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ba2789",
   "metadata": {},
   "source": [
    "We build a mock example of how data can be manipulated to be used as input in PyTorch Geometric.\n",
    "\n",
    "Let's assume we have a nested, ragged dataset, where each line represents a particle track. Each track is composed by `[x, y]` coordinates. Particles can travel short or longer distances, thus tracks can have variable length, thus variable `[x, y]` measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "837dc33f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>values</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entry</th>\n",
       "      <th>subentry</th>\n",
       "      <th>subsubentry</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>5.274530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.032760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>-3.512800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.748490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>5.274530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">6</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <td>-0.093750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>0.468750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>0</th>\n",
       "      <td>0.468750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.531250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              values\n",
       "entry subentry subsubentry          \n",
       "0     0        0            5.274530\n",
       "               1            1.032760\n",
       "      1        0           -3.512800\n",
       "               1            1.748490\n",
       "1     0        0            5.274530\n",
       "...                              ...\n",
       "6     0        1           -0.093750\n",
       "      1        0            0.468750\n",
       "               1           -0.078125\n",
       "      2        0            0.468750\n",
       "               1            0.531250\n",
       "\n",
       "[62 rows x 1 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [x, y] coordinates of the tracks\n",
    "tracks = ak.Array(\n",
    "    [\n",
    "        [[5.274530,\t1.032760], [-3.512800,\t1.748490]], # track 1\n",
    "        [[5.274530,\t1.032760], [-3.512800,\t1.748490], [-3.512800,\t1.748490]], # track 2\n",
    "        [[8.216300, 4.078440], [-0.791570, 3.494780], [16.389320, 5.293990], [10.386410, 0.108320], [-2.070700, 14.071400], [9.570210, -0.948230], [1.973320, 3.623800], [5.667600, 11.380010], [0.254970, 3.392760], [3.865850, 6.220510], [-0.673930, 2.205720]], # track 3\n",
    "        [[3.595280, 7.371910], [0.591920, 2.915030], [4.029320, -1.136010], [-1.015930, 1.958940], [1.036660, 0.052510]], # track 4\n",
    "        [[-8.785100, -0.004970], [-15.226880, 3.902440], [5.745930, 4.127180]], # track 5\n",
    "        [[4.406250, -6.953125], [4.343750, -7.093750], [4.312500, -7.140625], [4.140625, -7.140625]], # track 6\n",
    "        [[0.468750, -0.093750], [0.468750, -0.078125], [0.468750, 0.531250]] # track 7\n",
    "    ]\n",
    ")\n",
    "\n",
    "# visualise to a ragged pd DataFrame ;)\n",
    "ak.to_dataframe(tracks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9a6c83",
   "metadata": {},
   "source": [
    "Let's assume we want to break this \"track\" relationship and treat the data just as multiple `[x, y]` coordinates. We will use those cooridates to construct a Graph object using [`torch_geometric.data.Data`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html) class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f880075",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "422b2239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>[[5.27, 1.03],\n",
       " [-3.51, 1.75],\n",
       " [5.27, 1.03],\n",
       " [-3.51, 1.75],\n",
       " [-3.51, 1.75],\n",
       " [8.22, 4.08],\n",
       " [-0.792, 3.49],\n",
       " [16.4, 5.29],\n",
       " [10.4, 0.108],\n",
       " [-2.07, 14.1],\n",
       " ...,\n",
       " [-15.2, 3.9],\n",
       " [5.75, 4.13],\n",
       " [4.41, -6.95],\n",
       " [4.34, -7.09],\n",
       " [4.31, -7.14],\n",
       " [4.14, -7.14],\n",
       " [0.469, -0.0938],\n",
       " [0.469, -0.0781],\n",
       " [0.469, 0.531]]\n",
       "------------------------\n",
       "type: 31 * var * float64</pre>"
      ],
      "text/plain": [
       "<Array [[5.27, 1.03], [...], ..., [0.469, 0.531]] type='31 * var * float64'>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coordinates = ak.flatten(tracks)\n",
    "display(coordinates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175850ef",
   "metadata": {},
   "source": [
    "The above coordinates will be our node _features_. We will use Awkward to build the _edges_ of a fully connected Graph. This is currenly implemented in the custom function `get_edges` but ongoing developments in Awkward will allow such calculation natively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f46c11d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edges(nodes: ak.Array) -> torch.tensor:\n",
    "    '''\n",
    "    Calculate the edges of a fully connected graph.\n",
    "    Return tensor that can be directly used in torch_geometric.data.Data\n",
    "    '''\n",
    "    number_of_nodes = ak.num(nodes, axis=0)\n",
    "    counts = np.arange(0, number_of_nodes)\n",
    "    reversed_counts = counts[::-1]\n",
    "    \n",
    "    # calculate all possible edges in both directions using ak.combinations\n",
    "    combinations = ak.combinations(counts, 2, axis=0)\n",
    "    reversed_combinations = ak.combinations(reversed_counts, 2, axis=0)[::-1]\n",
    "    \n",
    "    # zip the two set of edges to a single Akward Array\n",
    "    # and convert it to a tensor\n",
    "    edge_index_tensor = torch.tensor( ak.to_list( ak.zip( [combinations, reversed_combinations] ) ), dtype=torch.long )\n",
    "    # get the right shape\n",
    "    edge_index_tensor = torch.flatten(edge_index_tensor).reshape(-1,2)\n",
    "    \n",
    "    return edge_index_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d647f1a0",
   "metadata": {},
   "source": [
    "Finally, we construct a `Data` object from `features_tensor` and an `edge_index_tensor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57873457",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_tensor = torch.tensor(ak.to_list(coordinates), dtype=torch.float)\n",
    "edge_index_tensor = get_edges(coordinates)\n",
    "\n",
    "data = Data(x=features_tensor, edge_index=edge_index_tensor.t().contiguous())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "071f96c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.num_nodes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scipy2024-tutorial-thinking-in-arrays",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
